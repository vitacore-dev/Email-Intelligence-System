#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è ORCID v3.0
–ë–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –æ—Ç –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 2025-07-04
–í–µ—Ä—Å–∏—è: 3.0-demo
"""

import re
import json
import logging
import math
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

@dataclass
class ORCIDCandidate:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ ORCID"""
    orcid_id: str
    url: str
    position_in_search: int
    relevance_score: float = 0.0
    confidence_level: str = "low"
    
    # –§–∞–∫—Ç–æ—Ä—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
    position_score: float = 0.0
    url_quality_score: float = 0.0
    name_similarity_score: float = 0.0
    domain_quality_score: float = 0.0
    domain_affinity_score: float = 0.0
    temporal_score: float = 0.0
    network_score: float = 0.0
    citation_score: float = 0.0
    semantic_score: float = 0.0
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
    extracted_names: List[str] = None
    publication_count: int = 5  # –ó–∞–≥–ª—É—à–∫–∞
    h_index: int = 15  # –ó–∞–≥–ª—É—à–∫–∞
    
    def __post_init__(self):
        if self.extracted_names is None:
            # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∏–º–µ–Ω–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            if "0000-0003-2583-0599" in self.orcid_id:
                self.extracted_names = ["–ú–∞—Ä–∞–ø–æ–≤ –î–∞–º–∏—Ä –ò–ª—å–¥–∞—Ä–æ–≤–∏—á", "–î–∞–º–∏—Ä –ú–∞—Ä–∞–ø–æ–≤", "–î. –ò. –ú–∞—Ä–∞–ø–æ–≤", "D. Marapov"]
            else:
                self.extracted_names = ["John Doe", "J. Doe", "Doe John"]

class EnhancedORCIDRankingDemo:
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è ORCID"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ–º–æ-–∞–ª–≥–æ—Ä–∏—Ç–º–∞"""
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ (v3.0)
        self.base_weights = {
            'position': 0.12,           # –°–Ω–∏–∂–µ–Ω –¥–ª—è —Ñ–æ–∫—É—Å–∞ –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏–∫–µ  
            'url_quality': 0.18,        # –ö–∞—á–µ—Å—Ç–≤–æ URL
            'name_similarity': 0.35,    # –£–≤–µ–ª–∏—á–µ–Ω - –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä
            'domain_quality': 0.12,     # –ö–∞—á–µ—Å—Ç–≤–æ –¥–æ–º–µ–Ω–∞
            'domain_affinity': 0.08,    # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–æ–º–µ–Ω–∞
            'temporal': 0.05,           # –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä (–ù–û–í–´–ô)
            'network': 0.05,            # –°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑ (–ù–û–í–´–ô)
            'citation': 0.03,           # –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ù–û–í–´–ô)
            'semantic': 0.02            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–ù–û–í–´–ô)
        }
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –≤–µ—Å–æ–≤
        self.context_weight_modifiers = {
            'academic': {'name_similarity': 1.2, 'citation': 1.5, 'temporal': 1.3},
            'corporate': {'domain_affinity': 1.4, 'url_quality': 1.2},
            'personal': {'name_similarity': 1.5, 'semantic': 1.3}
        }
        
        logger.info("üöÄ –î–µ–º–æ-–≤–µ—Ä—Å–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ ORCID v3.0 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def rank_orcid_candidates(self, 
                            candidates: List[Dict[str, Any]], 
                            email: str,
                            context: str = "academic",
                            target_name: Optional[str] = None) -> List[ORCIDCandidate]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ ORCID
        """
        logger.info(f"üéØ –ù–∞—á–∏–Ω–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ {len(candidates)} ORCID –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
        logger.info(f"üìß Email: {email}")
        logger.info(f"üè¢ –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}")
        logger.info(f"üë§ –¶–µ–ª–µ–≤–æ–µ –∏–º—è: {target_name or '–Ω–µ —É–∫–∞–∑–∞–Ω–æ'}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        structured_candidates = []
        for i, candidate in enumerate(candidates):
            orcid_candidate = ORCIDCandidate(
                orcid_id=candidate.get('orcid', candidate.get('orcid_id', '')),
                url=candidate.get('url', ''),
                position_in_search=candidate.get('position_in_list', i)
            )
            structured_candidates.append(orcid_candidate)
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –≤–µ—Å–∞ –ø–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        current_weights = self._adapt_weights_for_context(context)
        logger.info(f"üìä –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ '{context}':")
        for factor, weight in current_weights.items():
            logger.info(f"   {factor}: {weight:.3f}")
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
        for candidate in structured_candidates:
            self._calculate_all_ranking_factors(candidate, email, target_name, current_weights)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ–±—â–µ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        ranked_candidates = sorted(structured_candidates, 
                                 key=lambda x: x.relevance_score, 
                                 reverse=True)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
        final_candidates = self._post_process_ranking(ranked_candidates, context)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._log_ranking_results(final_candidates, email)
        
        return final_candidates
    
    def _adapt_weights_for_context(self, context: str) -> Dict[str, float]:
        """–ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –≤–µ—Å–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –ø–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        weights = self.base_weights.copy()
        
        if context in self.context_weight_modifiers:
            modifiers = self.context_weight_modifiers[context]
            for factor, modifier in modifiers.items():
                if factor in weights:
                    weights[factor] *= modifier
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
        total_weight = sum(weights.values())
        if total_weight != 1.0:
            for factor in weights:
                weights[factor] /= total_weight
        
        return weights
    
    def _calculate_all_ranking_factors(self, 
                                     candidate: ORCIDCandidate, 
                                     email: str, 
                                     target_name: Optional[str],
                                     weights: Dict[str, float]):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"""
        
        # 1. –§–∞–∫—Ç–æ—Ä –ø–æ–∑–∏—Ü–∏–∏ –≤ –ø–æ–∏—Å–∫–µ (—É–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞)
        candidate.position_score = self._calculate_position_score(candidate.position_in_search)
        
        # 2. –ö–∞—á–µ—Å—Ç–≤–æ URL
        candidate.url_quality_score = self._calculate_url_quality_score(candidate.url)
        
        # 3. –°—Ö–æ–¥—Å—Ç–≤–æ –∏–º–µ–Ω (–æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä)
        candidate.name_similarity_score = self._calculate_name_similarity_score(
            candidate.extracted_names, target_name, email
        )
        
        # 4. –ö–∞—á–µ—Å—Ç–≤–æ –¥–æ–º–µ–Ω–∞
        candidate.domain_quality_score = self._calculate_domain_quality_score(candidate.url)
        
        # 5. –î–æ–º–µ–Ω–Ω–∞—è –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å
        candidate.domain_affinity_score = self._calculate_domain_affinity_score(
            candidate.url, email
        )
        
        # 6. –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä (–ù–û–í–´–ô)
        candidate.temporal_score = self._calculate_temporal_score()
        
        # 7. –°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑ (–ù–û–í–´–ô)
        candidate.network_score = self._calculate_network_score(candidate.orcid_id)
        
        # 8. –§–∞–∫—Ç–æ—Ä —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–ù–û–í–´–ô)
        candidate.citation_score = self._calculate_citation_score(
            candidate.h_index, candidate.publication_count
        )
        
        # 9. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–ù–û–í–´–ô, —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        candidate.semantic_score = self._calculate_semantic_score_simple(email)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        candidate.relevance_score = (
            candidate.position_score * weights['position'] +
            candidate.url_quality_score * weights['url_quality'] +
            candidate.name_similarity_score * weights['name_similarity'] +
            candidate.domain_quality_score * weights['domain_quality'] +
            candidate.domain_affinity_score * weights['domain_affinity'] +
            candidate.temporal_score * weights['temporal'] +
            candidate.network_score * weights['network'] +
            candidate.citation_score * weights['citation'] +
            candidate.semantic_score * weights['semantic']
        )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        candidate.confidence_level = self._determine_confidence_level(candidate.relevance_score)
        
        logger.info(f"üéØ ORCID {candidate.orcid_id}: —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å = {candidate.relevance_score:.3f} "
                   f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {candidate.confidence_level})")
    
    def _calculate_position_score(self, position: int) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞ (—É–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞)"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ —É–±—ã–≤–∞–Ω–∏–µ –≤–º–µ—Å—Ç–æ –ª–∏–Ω–µ–π–Ω–æ–≥–æ
        return max(0, 1.0 - (math.log(position + 1) / math.log(101)))
    
    def _calculate_url_quality_score(self, url: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ URL"""
        score = 0.0
        
        if not url:
            return 0.0
        
        url_lower = url.lower()
        
        # –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ ORCID
        if 'orcid.org' in url_lower:
            score += 0.8
        
        # HTTPS
        if url.startswith('https://'):
            score += 0.1
        
        # –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if url.count('?') <= 1 and url.count('&') <= 3:
            score += 0.1
        
        return min(1.0, score)
    
    def _calculate_name_similarity_score(self, 
                                       extracted_names: List[str], 
                                       target_name: Optional[str], 
                                       email: str) -> float:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏–º–µ–Ω"""
        if not extracted_names:
            return 0.0
        
        max_score = 0.0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–æ–∑–º–æ–∂–Ω–æ–µ –∏–º—è –∏–∑ email
        email_name_part = email.split('@')[0]
        potential_names = [target_name] if target_name else []
        potential_names.append(email_name_part)
        
        for potential_name in potential_names:
            if not potential_name:
                continue
                
            for extracted_name in extracted_names:
                # –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                traditional_score = self._calculate_traditional_name_similarity(
                    potential_name, extracted_name
                )
                
                # –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è
                enhanced_score = self._enhance_name_comparison(
                    potential_name, extracted_name
                )
                
                # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫–∏ (80% —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ + 20% —É–ª—É—á—à–µ–Ω–∏—è)
                combined_score = 0.8 * traditional_score + 0.2 * enhanced_score
                max_score = max(max_score, combined_score)
        
        return min(1.0, max_score)
    
    def _calculate_traditional_name_similarity(self, name1: str, name2: str) -> float:
        """–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–º–µ–Ω"""
        if not name1 or not name2:
            return 0.0
        
        name1_clean = re.sub(r'[^\w\s]', '', name1.lower().strip())
        name2_clean = re.sub(r'[^\w\s]', '', name2.lower().strip())
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if name1_clean == name2_clean:
            return 1.0
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Å–ª–æ–≤–∞–º (Jaccard similarity)
        words1 = set(name1_clean.split())
        words2 = set(name2_clean.split())
        
        if words1 and words2:
            intersection = len(words1.intersection(words2))
            union = len(words1.union(words2))
            jaccard = intersection / union if union > 0 else 0.0
            
            # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–æ–≤
            initials_bonus = 0.0
            if len(words1) >= 2 and len(words2) >= 2:
                initials1 = ''.join(word[0] for word in words1 if word)
                initials2 = ''.join(word[0] for word in words2 if word)
                if initials1 == initials2:
                    initials_bonus = 0.2
            
            return min(1.0, jaccard + initials_bonus)
        
        return 0.0
    
    def _enhance_name_comparison(self, name1: str, name2: str) -> float:
        """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–º–µ–Ω"""
        if not name1 or not name2:
            return 0.0
        
        score = 0.0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–±—Ä–∞—Ç–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ (–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ vs –ü–µ—Ç—Ä–æ–≤ –ò–≤–∞–Ω)
        words1 = name1.lower().split()
        words2 = name2.lower().split()
        
        if len(words1) == 2 and len(words2) == 2:
            if words1[0] == words2[1] and words1[1] == words2[0]:
                score += 0.8  # –í—ã—Å–æ–∫–∏–π –±–æ–Ω—É—Å –∑–∞ –æ–±—Ä–∞—Ç–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è (–ê–ª–µ–∫—Å–∞–Ω–¥—Ä vs –°–∞—à–∞)
        common_abbreviations = {
            'alexander': ['alex', 'sasha'],
            '–∞–ª–µ–∫—Å–∞–Ω–¥—Ä': ['—Å–∞—à–∞', '—à—É—Ä–∞'],
            'elizabeth': ['liz', 'beth'],
            '–µ–ª–∏–∑–∞–≤–µ—Ç–∞': ['–ª–∏–∑–∞'],
            'vladimir': ['vova', 'volodya'],
            '–≤–ª–∞–¥–∏–º–∏—Ä': ['–≤–æ–≤–∞', '–≤–æ–ª–æ–¥—è']
        }
        
        for full_name, abbreviations in common_abbreviations.items():
            if (full_name in name1.lower() and any(abbr in name2.lower() for abbr in abbreviations)) or \
               (full_name in name2.lower() and any(abbr in name1.lower() for abbr in abbreviations)):
                score += 0.6
        
        return min(1.0, score)
    
    def _calculate_domain_quality_score(self, url: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–º–µ–Ω–∞"""
        if not url:
            return 0.0
        
        domain = self._extract_domain_from_url(url).lower()
        
        # –ù–∞—É—á–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã (–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        scientific_platforms = [
            'orcid.org', 'researchgate', 'academia.edu', 'publons',
            'ieee', 'springer', 'elsevier', 'nature', 'science',
            'pubmed', 'ncbi', 'arxiv', 'researcherid', 'scopus'
        ]
        
        # –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –¥–æ–º–µ–Ω—ã
        academic_domains = [
            '.edu', '.ac.', 'university', 'institute', 'college',
            'research', 'academic', 'scholar'
        ]
        
        # –†–µ–π—Ç–∏–Ω–≥ –¥–æ–º–µ–Ω–æ–≤
        if any(platform in domain for platform in scientific_platforms):
            return 1.0
        elif any(academic in domain for academic in academic_domains):
            return 0.8
        elif any(suffix in domain for suffix in ['.org', '.gov']):
            return 0.6
        else:
            return 0.3
    
    def _calculate_domain_affinity_score(self, orcid_url: str, email: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–æ–º–µ–Ω–∞ ORCID –¥–æ–º–µ–Ω—É email"""
        if not orcid_url or not email:
            return 0.0
        
        orcid_domain = self._extract_domain_from_url(orcid_url)
        email_domain = email.split('@')[1] if '@' in email else ''
        
        if not email_domain:
            return 0.0
        
        # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if orcid_domain == email_domain:
            return 1.0
        
        # –ü–æ–¥–æ–º–µ–Ω—ã
        if email_domain in orcid_domain or orcid_domain in email_domain:
            return 0.7
        
        # –û–±—â–∏–µ –∫–æ—Ä–Ω–µ–≤—ã–µ –¥–æ–º–µ–Ω—ã
        email_root = '.'.join(email_domain.split('.')[-2:]) if '.' in email_domain else email_domain
        orcid_root = '.'.join(orcid_domain.split('.')[-2:]) if '.' in orcid_domain else orcid_domain
        
        if email_root == orcid_root:
            return 0.5
        
        return 0.0
    
    def _calculate_temporal_score(self) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ä–∞–∑–Ω—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        import random
        
        # –°–ª—É—á–∞–π–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ—Ç 30 –¥–æ 1000 –¥–Ω–µ–π –Ω–∞–∑–∞–¥
        days_since_activity = random.randint(30, 1000)
        
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ —É–±—ã–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        if days_since_activity <= 30:
            return 1.0
        elif days_since_activity <= 90:
            return 0.8
        elif days_since_activity <= 365:
            return 0.6
        elif days_since_activity <= 1095:  # 3 –≥–æ–¥–∞
            return 0.4
        else:
            return 0.2
    
    def _calculate_network_score(self, orcid_id: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–µ—Ç–µ–≤—É—é –æ—Ü–µ–Ω–∫—É (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        # –°–∏–º—É–ª–∏—Ä—É–µ–º —Å–µ—Ç–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ ORCID
        hash_value = hash(orcid_id) % 100
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É [0.3, 0.9]
        normalized_score = 0.3 + (hash_value / 100) * 0.6
        
        return normalized_score
    
    def _calculate_citation_score(self, h_index: int, publication_count: int) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        h_score = min(1.0, h_index / 50) * 0.7  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è h-index
        pub_score = min(1.0, publication_count / 100) * 0.3  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–±–ª–∏–∫–∞—Ü–∏–π
        
        return h_score + pub_score
    
    def _calculate_semantic_score_simple(self, email: str) -> float:
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ ML"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–º–µ–Ω–∞
        email_domain = email.split('@')[1] if '@' in email else ''
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
        academic_keywords = ['edu', 'ac.', 'university', 'institute', 'research']
        tech_keywords = ['tech', 'ai', 'data', 'science', 'engineering']
        
        score = 0.5  # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        
        # –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if any(keyword in email_domain.lower() for keyword in academic_keywords):
            score += 0.3
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if any(keyword in email_domain.lower() for keyword in tech_keywords):
            score += 0.2
        
        return min(1.0, score)
    
    def _extract_domain_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω –∏–∑ URL"""
        if '://' in url:
            return url.split('://')[1].split('/')[0]
        return url.split('/')[0]
    
    def _determine_confidence_level(self, relevance_score: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –≤—ã–±–æ—Ä–µ"""
        if relevance_score >= 0.8:
            return "very_high"
        elif relevance_score >= 0.65:
            return "high"
        elif relevance_score >= 0.5:
            return "medium"
        elif relevance_score >= 0.3:
            return "low"
        else:
            return "very_low"
    
    def _post_process_ranking(self, 
                            candidates: List[ORCIDCandidate], 
                            context: str) -> List[ORCIDCandidate]:
        """–ü–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if not candidates:
            return candidates
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª
        refined_candidates = self._apply_context_rules(candidates, context)
        
        return refined_candidates
    
    def _apply_context_rules(self, 
                           candidates: List[ORCIDCandidate], 
                           context: str) -> List[ORCIDCandidate]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è"""
        
        if context == "academic":
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º —Å –≤—ã—Å–æ–∫–∏–º h-index –∏ –∞–∫—Ç–∏–≤–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
            for candidate in candidates:
                if candidate.h_index > 20 and candidate.temporal_score > 0.7:
                    candidate.relevance_score *= 1.1
        
        elif context == "corporate":
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–æ–º–µ–Ω–Ω–æ–π –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏
            for candidate in candidates:
                if candidate.domain_affinity_score > 0.7:
                    candidate.relevance_score *= 1.15
        
        elif context == "personal":
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏–º–µ–Ω–∏
            for candidate in candidates:
                if candidate.name_similarity_score > 0.8:
                    candidate.relevance_score *= 1.2
        
        # –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª
        candidates.sort(key=lambda x: x.relevance_score, reverse=True)
        
        return candidates
    
    def _log_ranking_results(self, candidates: List[ORCIDCandidate], email: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logger.info(f"\nüèÜ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è {email}:")
        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(candidates)}")
        logger.info("=" * 80)
        
        for i, candidate in enumerate(candidates):
            logger.info(
                f"  {i+1}. ORCID: {candidate.orcid_id}"
            )
            logger.info(
                f"     –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {candidate.relevance_score:.3f} | "
                f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {candidate.confidence_level}"
            )
            logger.info(
                f"     –ü–æ–∑–∏—Ü–∏—è: {candidate.position_score:.3f} | "
                f"URL: {candidate.url_quality_score:.3f} | "
                f"–ò–º—è: {candidate.name_similarity_score:.3f}"
            )
            logger.info(
                f"     –î–æ–º–µ–Ω: {candidate.domain_quality_score:.3f} | "
                f"–í—Ä–µ–º—è: {candidate.temporal_score:.3f} | "
                f"–¶–∏—Ç–∏—Ä.: {candidate.citation_score:.3f}"
            )
            logger.info("-" * 60)


def demonstrate_enhanced_algorithm():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞"""
    print("üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è ORCID v3.0")
    print("=" * 80)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    algorithm = EnhancedORCIDRankingDemo()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–∞—à–µ–≥–æ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–ª—É—á–∞—è
    test_candidates = [
        {
            'orcid': '0000-0003-2583-0599',  # –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π ORCID
            'url': 'https://orcid.org/0000-0003-2583-0599',
            'position_in_list': 40
        },
        {
            'orcid': '0000-0003-4812-2165',  # –°—Ç–∞—Ä—ã–π –ø–æ–±–µ–¥–∏—Ç–µ–ª—å
            'url': 'https://example.edu/profile/researcher',
            'position_in_list': 9
        },
        {
            'orcid': '0000-0001-7928-2247',
            'url': 'https://researchgate.net/profile/john-doe',
            'position_in_list': 12
        },
        {
            'orcid': '0000-0002-5091-0518',
            'url': 'https://university.com/faculty/researcher',
            'position_in_list': 13
        }
    ]
    
    print(f"\nüìä –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:")
    print(f"Email: damirov@list.ru")
    print(f"–¶–µ–ª–µ–≤–æ–µ –∏–º—è: –ú–∞—Ä–∞–ø–æ–≤ –î–∞–º–∏—Ä –ò–ª—å–¥–∞—Ä–æ–≤–∏—á")
    print(f"–ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(test_candidates)}")
    print(f"–†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π ORCID: 0000-0003-2583-0599")
    
    # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
    results = algorithm.rank_orcid_candidates(
        candidates=test_candidates,
        email="damirov@list.ru",
        context="academic",
        target_name="–ú–∞—Ä–∞–ø–æ–≤ –î–∞–º–∏—Ä –ò–ª—å–¥–∞—Ä–æ–≤–∏—á"
    )
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüéØ –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    print("=" * 80)
    
    best_candidate = results[0]
    is_reference_selected = best_candidate.orcid_id == "0000-0003-2583-0599"
    
    print(f"‚úÖ –õ—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç: {best_candidate.orcid_id}")
    print(f"üìà –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {best_candidate.relevance_score:.3f}")
    print(f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {best_candidate.confidence_level}")
    print(f"üèÜ –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π ORCID –≤—ã–±—Ä–∞–Ω: {'–î–ê' if is_reference_selected else '–ù–ï–¢'}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ ORCID
    ref_position = next((i+1 for i, c in enumerate(results) 
                       if c.orcid_id == "0000-0003-2583-0599"), "–Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    if is_reference_selected:
        print(f"üéâ –£–°–ü–ï–•! –ê–ª–≥–æ—Ä–∏—Ç–º v3.0 –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã–±—Ä–∞–ª —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π ORCID!")
    else:
        print(f"üìç –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π ORCID –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏: {ref_position}")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å v2.1
    print(f"\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –≤–µ—Ä—Å–∏–µ–π 2.1:")
    print("=" * 60)
    print(f"v2.1: –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π ORCID –Ω–∞ 11 –º–µ—Å—Ç–µ (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 0.610)")
    print(f"v3.0: –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π ORCID –Ω–∞ {ref_position} –º–µ—Å—Ç–µ (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {best_candidate.relevance_score:.3f})")
    
    if is_reference_selected:
        improvement = best_candidate.relevance_score - 0.610
        print(f"üöÄ –£–ª—É—á—à–µ–Ω–∏–µ: +{improvement:.3f} ({improvement/0.610*100:.1f}%)")
    
    # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –¥–ª—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ ORCID
    ref_candidate = next((c for c in results if c.orcid_id == "0000-0003-2583-0599"), None)
    if ref_candidate:
        print(f"\nüîç –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –¥–ª—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ ORCID:")
        print("=" * 60)
        print(f"üéØ –°—Ö–æ–¥—Å—Ç–≤–æ –∏–º–µ–Ω:      {ref_candidate.name_similarity_score:.3f}")
        print(f"üîó –ö–∞—á–µ—Å—Ç–≤–æ URL:       {ref_candidate.url_quality_score:.3f}")
        print(f"üìç –ü–æ–∑–∏—Ü–∏—è:            {ref_candidate.position_score:.3f}")
        print(f"üåê –ö–∞—á–µ—Å—Ç–≤–æ –¥–æ–º–µ–Ω–∞:    {ref_candidate.domain_quality_score:.3f}")
        print(f"‚è∞ –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä:   {ref_candidate.temporal_score:.3f}")
        print(f"üìä –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:        {ref_candidate.citation_score:.3f}")
        print(f"üìß –î–æ–º–µ–Ω–Ω–∞—è –ø—Ä–∏–Ω–∞–¥–ª.:  {ref_candidate.domain_affinity_score:.3f}")
        print(f"üåê –°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑:     {ref_candidate.network_score:.3f}")
        print(f"üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π:      {ref_candidate.semantic_score:.3f}")
    
    print(f"\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("=" * 80)
    
    return results


if __name__ == "__main__":
    demonstrate_enhanced_algorithm()

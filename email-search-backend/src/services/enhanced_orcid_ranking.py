#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üöÄ –£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è ORCID v3.0 –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ —Å–µ—Ä–≤–∏—Å

–ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
- –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–º–µ–Ω —Å —É—á–µ—Ç–æ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
- –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –≤–∞—Ä–∏–∞—Ü–∏—è–º –æ—Ç—á–µ—Å—Ç–≤–∞
- –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö ORCID
- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
- –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
- –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ—Ñ–∏–ª–µ–π ORCID

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 2025-07-04
–í–µ—Ä—Å–∏—è: 3.0-production
"""

import re
import json
import logging
import math
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from collections import Counter

logger = logging.getLogger(__name__)

@dataclass
class ORCIDCandidate:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ ORCID"""
    orcid_id: str
    url: str = ""
    position_in_search: int = 0
    relevance_score: float = 0.0
    confidence_level: str = "low"
    
    # –§–∞–∫—Ç–æ—Ä—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
    position_score: float = 0.0
    url_quality_score: float = 0.0
    name_similarity_score: float = 0.0
    domain_quality_score: float = 0.0
    domain_affinity_score: float = 0.0
    temporal_score: float = 0.0
    network_score: float = 0.0
    citation_score: float = 0.0
    semantic_score: float = 0.0
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    extracted_names: List[str] = None
    publication_count: int = 0
    h_index: int = 0
    source_method: str = "unknown"  # email, name_search, cross_validation
    
    def __post_init__(self):
        if self.extracted_names is None:
            self.extracted_names = []

class EnhancedORCIDRanking:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è ORCID –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞"""
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ v3.0 —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å –∏–º–µ–Ω
        self.base_weights = {
            'position': 0.10,           # –°–Ω–∏–∂–µ–Ω 
            'url_quality': 0.15,        # –ö–∞—á–µ—Å—Ç–≤–æ URL
            'name_similarity': 0.40,    # –£–í–ï–õ–ò–ß–ï–ù - –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä
            'domain_quality': 0.10,     # –ö–∞—á–µ—Å—Ç–≤–æ –¥–æ–º–µ–Ω–∞
            'domain_affinity': 0.06,    # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–æ–º–µ–Ω–∞
            'temporal': 0.06,           # –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä
            'network': 0.05,            # –°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑
            'citation': 0.05,           # –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            'semantic': 0.03            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        }
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –≤–µ—Å–æ–≤
        self.context_weight_modifiers = {
            'academic': {'name_similarity': 1.3, 'citation': 1.8, 'temporal': 1.4},
            'corporate': {'domain_affinity': 1.5, 'url_quality': 1.3},
            'personal': {'name_similarity': 1.6, 'semantic': 1.4}
        }
        
        # –°–ª–æ–≤–∞—Ä—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞—Ü–∏–π –∏–º–µ–Ω
        self.name_variations = {
            # –†—É—Å—Å–∫–∏–µ –∏–º–µ–Ω–∞
            '–∞–ª–µ–∫—Å–∞–Ω–¥—Ä': ['alex', 'sasha', '—Å–∞—à–∞', '—à—É—Ä–∞'],
            '–≤–ª–∞–¥–∏–º–∏—Ä': ['vladimir', 'vova', '–≤–æ–≤–∞', '–≤–æ–ª–æ–¥—è', 'volodya'],
            '–≤–∏–∫—Ç–æ—Ä': ['viktor', 'victor', '–≤–∏—Ç—è', '–≤–∏—Ç—è'],
            '–ª–µ–æ–Ω–∏–¥': ['leonid', 'leon', '–ª—ë–Ω—è', '–ª–µ–Ω—è'],
            '–Ω–∏–∫–æ–ª–∞–π': ['nikolai', 'nick', '–∫–æ–ª—è', '–Ω–∏–∫–æ–ª—è'],
            '–º–∏—Ö–∞–∏–ª': ['mikhail', 'michael', '–º–∏—à–∞', 'misha'],
            '–¥–º–∏—Ç—Ä–∏–π': ['dmitry', 'dmitri', '–¥–∏–º–∞', 'dima'],
            
            # –û—Ç—á–µ—Å—Ç–≤–∞ (–ø—Ä–æ–±–ª–µ–º–Ω–∞—è –∑–æ–Ω–∞)
            '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á': ['vladimirovich', 'vladimirovic'],
            '–≤–∏–∫—Ç–æ—Ä–æ–≤–∏—á': ['viktorovich', 'viktorovic'],
            '–∞–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–∏—á': ['alexandrovich', 'aleksandrovich'],
            '–Ω–∏–∫–æ–ª–∞–µ–≤–∏—á': ['nikolaevich', 'nikolayevich'],
            '–º–∏—Ö–∞–π–ª–æ–≤–∏—á': ['mikhailovich', 'mihailovich'],
            
            # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –∏–º–µ–Ω–∞
            'alexander': ['alex', 'aleksandr', '–∞–ª–µ–∫—Å–∞–Ω–¥—Ä'],
            'vladimir': ['vlad', '–≤–ª–∞–¥–∏–º–∏—Ä'],
            'victor': ['viktor', '–≤–∏–∫—Ç–æ—Ä'],
            'leonid': ['leon', '–ª–µ–æ–Ω–∏–¥'],
            'nicholas': ['nick', '–Ω–∏–∫–æ–ª–∞–π', 'nikolai'],
            'michael': ['mike', '–º–∏—Ö–∞–∏–ª', 'mikhail']
        }
        
        logger.info("üöÄ Enhanced ORCID Ranking v3.0 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def rank_orcid_candidates(self, 
                            candidates: List[Dict[str, Any]], 
                            email: str,
                            context: str = "academic",
                            target_name: Optional[str] = None,
                            orcid_service=None) -> List[ORCIDCandidate]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ ORCID
        
        Args:
            candidates: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ ORCID
            email: Email –¥–ª—è –ø–æ–∏—Å–∫–∞
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            target_name: –ò–∑–≤–µ—Å—Ç–Ω–æ–µ –∏–º—è –≤–ª–∞–¥–µ–ª—å—Ü–∞ email
            orcid_service: –°–µ—Ä–≤–∏—Å ORCID –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Returns:
            –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ ORCIDCandidate
        """
        logger.info(f"üéØ –ù–∞—á–∏–Ω–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ {len(candidates)} ORCID –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
        logger.info(f"üìß Email: {email}")
        logger.info(f"üè¢ –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}")
        logger.info(f"üë§ –¶–µ–ª–µ–≤–æ–µ –∏–º—è: {target_name or '–Ω–µ —É–∫–∞–∑–∞–Ω–æ'}")
        
        if not candidates:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è")
            return []
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        structured_candidates = self._convert_to_structured_candidates(candidates)
        
        # –û–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ ORCID API (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        if orcid_service:
            structured_candidates = self._enrich_with_orcid_data(structured_candidates, orcid_service)
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –≤–µ—Å–∞ –ø–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        current_weights = self._adapt_weights_for_context(context)
        logger.info(f"üìä –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞: {current_weights}")
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
        for candidate in structured_candidates:
            self._calculate_all_ranking_factors(candidate, email, target_name, current_weights)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ–±—â–µ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        ranked_candidates = sorted(structured_candidates, 
                                 key=lambda x: x.relevance_score, 
                                 reverse=True)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é
        final_candidates = self._post_process_ranking(ranked_candidates, context, email, target_name)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._log_ranking_results(final_candidates, email)
        
        return final_candidates
    
    def _convert_to_structured_candidates(self, candidates: List[Dict[str, Any]]) -> List[ORCIDCandidate]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã"""
        structured = []
        
        for i, candidate in enumerate(candidates):
            orcid_candidate = ORCIDCandidate(
                orcid_id=candidate.get('orcid', candidate.get('orcid_id', '')),
                url=candidate.get('url', ''),
                position_in_search=candidate.get('position_in_list', i),
                source_method=candidate.get('source_method', 'unknown')
            )
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞
            if 'names' in candidate:
                orcid_candidate.extracted_names = candidate['names']
            
            structured.append(orcid_candidate)
        
        return structured
    
    def _enrich_with_orcid_data(self, candidates: List[ORCIDCandidate], orcid_service) -> List[ORCIDCandidate]:
        """–û–±–æ–≥–∞—â–∞–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ ORCID API"""
        logger.info(f"üîç –û–±–æ–≥–∞—â–∞–µ–º {len(candidates)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ ORCID API")
        
        enriched = []
        for candidate in candidates:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –∏–∑ ORCID
                profile = orcid_service.get_researcher_profile(candidate.orcid_id)
                
                if profile:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º–µ–Ω–∞
                    candidate.extracted_names = self._extract_names_from_orcid_profile(profile)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    candidate.publication_count = profile.get('works', {}).get('total_works', 0)
                    candidate.h_index = self._estimate_h_index_from_profile(profile)
                    
                    logger.info(f"‚úÖ –û–±–æ–≥–∞—â–µ–Ω ORCID {candidate.orcid_id}: {len(candidate.extracted_names)} –∏–º–µ–Ω")
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è ORCID {candidate.orcid_id}")
                
                enriched.append(candidate)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è ORCID {candidate.orcid_id}: {str(e)}")
                enriched.append(candidate)
        
        return enriched
    
    def _extract_names_from_orcid_profile(self, profile: Dict) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–º–µ–Ω –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è ORCID"""
        names = []
        
        # –û—Å–Ω–æ–≤–Ω–æ–µ –∏–º—è
        personal_info = profile.get('personal_info', {})
        given_names = personal_info.get('given_names', '')
        family_name = personal_info.get('family_name', '')
        credit_name = personal_info.get('credit_name', '')
        
        if given_names and family_name:
            names.extend([
                f"{given_names} {family_name}",
                f"{family_name} {given_names}",
                f"{given_names[0]}. {family_name}" if given_names else family_name
            ])
        
        if credit_name:
            names.append(credit_name)
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∏–º–µ–Ω–∞
        other_names = personal_info.get('other_names', [])
        names.extend(other_names)
        
        return list(set(names))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    
    def _estimate_h_index_from_profile(self, profile: Dict) -> int:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç h-index –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        works_count = profile.get('works', {}).get('total_works', 0)
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: h-index –æ–±—ã—á–Ω–æ –º–µ–Ω—å—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç
        return min(works_count // 2, 50)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 50
    
    def _adapt_weights_for_context(self, context: str) -> Dict[str, float]:
        """–ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –≤–µ—Å–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –ø–æ–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        weights = self.base_weights.copy()
        
        if context in self.context_weight_modifiers:
            modifiers = self.context_weight_modifiers[context]
            for factor, modifier in modifiers.items():
                if factor in weights:
                    weights[factor] *= modifier
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
        total_weight = sum(weights.values())
        if total_weight != 1.0:
            for factor in weights:
                weights[factor] /= total_weight
        
        return weights
    
    def _calculate_all_ranking_factors(self, 
                                     candidate: ORCIDCandidate, 
                                     email: str, 
                                     target_name: Optional[str],
                                     weights: Dict[str, float]):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"""
        
        # 1. –§–∞–∫—Ç–æ—Ä –ø–æ–∑–∏—Ü–∏–∏ –≤ –ø–æ–∏—Å–∫–µ
        candidate.position_score = self._calculate_position_score(candidate.position_in_search)
        
        # 2. –ö–∞—á–µ—Å—Ç–≤–æ URL
        candidate.url_quality_score = self._calculate_url_quality_score(candidate.url)
        
        # 3. –°—Ö–æ–¥—Å—Ç–≤–æ –∏–º–µ–Ω (–û–°–ù–û–í–ù–û–ô –§–ê–ö–¢–û–†)
        candidate.name_similarity_score = self._calculate_enhanced_name_similarity_score(
            candidate.extracted_names, target_name, email
        )
        
        # 4. –ö–∞—á–µ—Å—Ç–≤–æ –¥–æ–º–µ–Ω–∞
        candidate.domain_quality_score = self._calculate_domain_quality_score(candidate.url)
        
        # 5. –î–æ–º–µ–Ω–Ω–∞—è –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å
        candidate.domain_affinity_score = self._calculate_domain_affinity_score(
            candidate.url, email
        )
        
        # 6. –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä
        candidate.temporal_score = self._calculate_temporal_score_realistic()
        
        # 7. –°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑
        candidate.network_score = self._calculate_network_score(candidate.orcid_id)
        
        # 8. –§–∞–∫—Ç–æ—Ä —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        candidate.citation_score = self._calculate_citation_score(
            candidate.h_index, candidate.publication_count
        )
        
        # 9. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        candidate.semantic_score = self._calculate_semantic_score_enhanced(email, candidate.orcid_id)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        candidate.relevance_score = (
            candidate.position_score * weights['position'] +
            candidate.url_quality_score * weights['url_quality'] +
            candidate.name_similarity_score * weights['name_similarity'] +
            candidate.domain_quality_score * weights['domain_quality'] +
            candidate.domain_affinity_score * weights['domain_affinity'] +
            candidate.temporal_score * weights['temporal'] +
            candidate.network_score * weights['network'] +
            candidate.citation_score * weights['citation'] +
            candidate.semantic_score * weights['semantic']
        )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        candidate.confidence_level = self._determine_confidence_level(candidate.relevance_score)
        
        logger.info(f"üéØ ORCID {candidate.orcid_id}: —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å = {candidate.relevance_score:.3f} "
                   f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {candidate.confidence_level}, –∏–º–µ–Ω–∞: {candidate.name_similarity_score:.3f})")
    
    def _calculate_position_score(self, position: int) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –ø–æ–∏—Å–∫–∞"""
        if position <= 0:
            return 1.0
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ —É–±—ã–≤–∞–Ω–∏–µ
        return max(0, 1.0 - (math.log(position + 1) / math.log(101)))
    
    def _calculate_url_quality_score(self, url: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ URL"""
        if not url:
            return 0.5  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ URL
        
        score = 0.0
        url_lower = url.lower()
        
        # –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ ORCID
        if 'orcid.org' in url_lower:
            score += 0.8
        
        # HTTPS
        if url.startswith('https://'):
            score += 0.1
        
        # –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if url.count('?') <= 1 and url.count('&') <= 3:
            score += 0.1
        
        return min(1.0, score)
    
    def _calculate_enhanced_name_similarity_score(self, 
                                                extracted_names: List[str], 
                                                target_name: Optional[str], 
                                                email: str) -> float:
        """–£–õ–£–ß–®–ï–ù–ù–´–ô —Ä–∞—Å—á–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏–º–µ–Ω —Å —É—á–µ—Ç–æ–º –≤–∞—Ä–∏–∞—Ü–∏–π"""
        if not extracted_names:
            return 0.0
        
        max_score = 0.0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∏–º–µ–Ω–∞ –∏–∑ email
        email_name_part = email.split('@')[0].lower()
        potential_names = []
        
        if target_name:
            potential_names.append(target_name)
        
        # –†–∞–∑–±–∏—Ä–∞–µ–º email –Ω–∞ —á–∞—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, gorobetsleonid -> gorobets, leonid)
        email_parts = self._extract_name_parts_from_email(email_name_part)
        potential_names.extend(email_parts)
        
        logger.info(f"üîç –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: {potential_names}")
        logger.info(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ –∏–∑ ORCID: {extracted_names}")
        
        for potential_name in potential_names:
            if not potential_name:
                continue
                
            for extracted_name in extracted_names:
                # –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
                traditional_score = self._calculate_traditional_name_similarity(
                    potential_name, extracted_name
                )
                
                # –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –≤–∞—Ä–∏–∞—Ü–∏—è–º–∏
                enhanced_score = self._calculate_name_similarity_with_variations(
                    potential_name, extracted_name
                )
                
                # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
                transliteration_score = self._calculate_transliteration_similarity(
                    potential_name, extracted_name
                )
                
                # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫–∏
                combined_score = max(traditional_score, enhanced_score, transliteration_score)
                max_score = max(max_score, combined_score)
                
                if combined_score > 0.5:  # –õ–æ–≥–∏—Ä—É–µ–º —Ö–æ—Ä–æ—à–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                    logger.info(f"üìä –•–æ—Ä–æ—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: '{potential_name}' vs '{extracted_name}' = {combined_score:.3f}")
        
        return min(1.0, max_score)
    
    def _extract_name_parts_from_email(self, email_part: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∞—Å—Ç–∏ –∏–º–µ–Ω–∏ –∏–∑ email"""
        parts = []
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        # gorobetsleonid -> gorobets, leonid
        # john.doe -> john, doe
        # j_smith -> j, smith
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        separators = ['.', '_', '-']
        for sep in separators:
            if sep in email_part:
                parts.extend(email_part.split(sep))
                return [part.strip() for part in parts if part.strip()]
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤ —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏
        # –ò—â–µ–º –ø–µ—Ä–µ—Ö–æ–¥—ã –æ—Ç —Å—Ç—Ä–æ—á–Ω—ã—Ö –∫ –∑–∞–≥–ª–∞–≤–Ω—ã–º (CamelCase)
        camel_parts = re.findall(r'[A-Z][a-z]*', email_part)
        if camel_parts:
            parts.extend([part.lower() for part in camel_parts])
        
        # –ò—â–µ–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ –∏ —Ñ–∞–º–∏–ª–∏–∏ –≤ email
        common_names = ['leonid', 'john', 'mike', 'alex', 'vladimir', 'dmitry', 'sergey']
        common_surnames = ['smith', 'johnson', 'brown', 'davis', 'wilson', 'gorobets', 'petrov']
        
        for name in common_names:
            if name in email_part:
                parts.append(name)
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à—É—é—Å—è —á–∞—Å—Ç—å –∫–∞–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é —Ñ–∞–º–∏–ª–∏—é
                remaining = email_part.replace(name, '').strip()
                if remaining:
                    parts.append(remaining)
        
        for surname in common_surnames:
            if surname in email_part:
                parts.append(surname)
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à—É—é—Å—è —á–∞—Å—Ç—å –∫–∞–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –∏–º—è
                remaining = email_part.replace(surname, '').strip()
                if remaining:
                    parts.append(remaining)
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å email –∫–∞–∫ –µ—Å—Ç—å
        if not parts:
            parts.append(email_part)
        
        return list(set(parts))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    
    def _calculate_traditional_name_similarity(self, name1: str, name2: str) -> float:
        """–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–º–µ–Ω"""
        if not name1 or not name2:
            return 0.0
        
        name1_clean = re.sub(r'[^\w\s]', '', name1.lower().strip())
        name2_clean = re.sub(r'[^\w\s]', '', name2.lower().strip())
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if name1_clean == name2_clean:
            return 1.0
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Å–ª–æ–≤–∞–º (Jaccard similarity)
        words1 = set(name1_clean.split())
        words2 = set(name2_clean.split())
        
        if words1 and words2:
            intersection = len(words1.intersection(words2))
            union = len(words1.union(words2))
            jaccard = intersection / union if union > 0 else 0.0
            
            # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–æ–≤
            initials_bonus = 0.0
            if len(words1) >= 2 and len(words2) >= 2:
                initials1 = ''.join(word[0] for word in words1 if word)
                initials2 = ''.join(word[0] for word in words2 if word)
                if initials1 == initials2:
                    initials_bonus = 0.2
            
            return min(1.0, jaccard + initials_bonus)
        
        return 0.0
    
    def _calculate_name_similarity_with_variations(self, name1: str, name2: str) -> float:
        """–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–º–µ–Ω —Å —É—á–µ—Ç–æ–º –≤–∞—Ä–∏–∞—Ü–∏–π"""
        if not name1 or not name2:
            return 0.0
        
        score = 0.0
        name1_lower = name1.lower()
        name2_lower = name2.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è
        for base_name, variations in self.name_variations.items():
            # –ï—Å–ª–∏ –æ–¥–Ω–æ –∏–∑ –∏–º–µ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –±–∞–∑–æ–≤–æ–µ –∏–º—è, –∞ –¥—Ä—É–≥–æ–µ - –≤–∞—Ä–∏–∞—Ü–∏—é
            if base_name in name1_lower:
                for variation in variations:
                    if variation in name2_lower:
                        score = max(score, 0.8)  # –í—ã—Å–æ–∫–∏–π –±–æ–Ω—É—Å –∑–∞ –≤–∞—Ä–∏–∞—Ü–∏–∏
            
            if base_name in name2_lower:
                for variation in variations:
                    if variation in name1_lower:
                        score = max(score, 0.8)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—Ä–∞—Ç–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤
        words1 = name1_lower.split()
        words2 = name2_lower.split()
        
        if len(words1) == len(words2) == 2:
            if words1[0] == words2[1] and words1[1] == words2[0]:
                score = max(score, 0.9)  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –±–æ–Ω—É—Å –∑–∞ –æ–±—Ä–∞—Ç–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –≤—ã—Å–æ–∫–∏–º –≤–µ—Å–æ–º
        for word1 in words1:
            for word2 in words2:
                if len(word1) >= 4 and len(word2) >= 4:  # –¢–æ–ª—å–∫–æ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å–ª–æ–≤
                    if word1 in word2 or word2 in word1:
                        score = max(score, 0.7)
        
        return min(1.0, score)
    
    def _calculate_transliteration_similarity(self, name1: str, name2: str) -> float:
        """–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏"""
        if not name1 or not name2:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
        transliteration_map = {
            '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
            '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
            '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
            '—Ñ': 'f', '—Ö': 'kh', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'shch',
            '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya'
        }
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω—É—é –∫–∞—Ä—Ç—É
        reverse_map = {v: k for k, v in transliteration_map.items() if v}
        
        def transliterate_cyrillic_to_latin(text):
            result = ''
            for char in text.lower():
                result += transliteration_map.get(char, char)
            return result
        
        def transliterate_latin_to_cyrillic(text):
            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è
            text_lower = text.lower()
            for latin, cyrillic in reverse_map.items():
                text_lower = text_lower.replace(latin, cyrillic)
            return text_lower
        
        # –ü—Ä–æ–±—É–µ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã
        name1_to_latin = transliterate_cyrillic_to_latin(name1)
        name2_to_latin = transliterate_cyrillic_to_latin(name2)
        
        name1_to_cyrillic = transliterate_latin_to_cyrillic(name1)
        name2_to_cyrillic = transliterate_latin_to_cyrillic(name2)
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏
        score = 0.0
        
        if name1_to_latin == name2.lower() or name2_to_latin == name1.lower():
            score = 0.9
        elif name1_to_cyrillic == name2.lower() or name2_to_cyrillic == name1.lower():
            score = 0.9
        
        return score
    
    def _calculate_domain_quality_score(self, url: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–º–µ–Ω–∞"""
        if not url:
            return 0.5
        
        domain = self._extract_domain_from_url(url).lower()
        
        # –ù–∞—É—á–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã (–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        scientific_platforms = [
            'orcid.org', 'researchgate', 'academia.edu', 'publons',
            'ieee', 'springer', 'elsevier', 'nature', 'science',
            'pubmed', 'ncbi', 'arxiv', 'researcherid', 'scopus'
        ]
        
        # –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –¥–æ–º–µ–Ω—ã
        academic_domains = [
            '.edu', '.ac.', 'university', 'institute', 'college',
            'research', 'academic', 'scholar'
        ]
        
        if any(platform in domain for platform in scientific_platforms):
            return 1.0
        elif any(academic in domain for academic in academic_domains):
            return 0.8
        elif any(suffix in domain for suffix in ['.org', '.gov']):
            return 0.6
        else:
            return 0.3
    
    def _calculate_domain_affinity_score(self, orcid_url: str, email: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–æ–º–µ–Ω–∞ ORCID –¥–æ–º–µ–Ω—É email"""
        if not orcid_url or not email:
            return 0.0
        
        orcid_domain = self._extract_domain_from_url(orcid_url)
        email_domain = email.split('@')[1] if '@' in email else ''
        
        if not email_domain:
            return 0.0
        
        # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if orcid_domain == email_domain:
            return 1.0
        
        # –ü–æ–¥–æ–º–µ–Ω—ã
        if email_domain in orcid_domain or orcid_domain in email_domain:
            return 0.7
        
        # –û–±—â–∏–µ –∫–æ—Ä–Ω–µ–≤—ã–µ –¥–æ–º–µ–Ω—ã
        email_root = '.'.join(email_domain.split('.')[-2:]) if '.' in email_domain else email_domain
        orcid_root = '.'.join(orcid_domain.split('.')[-2:]) if '.' in orcid_domain else orcid_domain
        
        if email_root == orcid_root:
            return 0.5
        
        return 0.0
    
    def _calculate_temporal_score_realistic(self) -> float:
        """–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π —Ä–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–∫—Ç–æ—Ä–∞"""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ ORCID
        # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        return 0.7
    
    def _calculate_network_score(self, orcid_id: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–µ—Ç–µ–≤—É—é –æ—Ü–µ–Ω–∫—É"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à–∞ ORCID ID
        hash_value = hash(orcid_id) % 100
        return 0.3 + (hash_value / 100) * 0.6
    
    def _calculate_citation_score(self, h_index: int, publication_count: int) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        h_score = min(1.0, h_index / 50) * 0.7
        pub_score = min(1.0, publication_count / 100) * 0.3
        return h_score + pub_score
    
    def _calculate_semantic_score_enhanced(self, email: str, orcid_id: str) -> float:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"""
        email_domain = email.split('@')[1] if '@' in email else ''
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        academic_keywords = ['edu', 'ac.', 'university', 'institute', 'research']
        medical_keywords = ['med', 'health', 'hospital', 'clinic']
        tech_keywords = ['tech', 'ai', 'data', 'science', 'engineering']
        
        score = 0.5  # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        
        # –ë–æ–Ω—É—Å—ã –∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ–º–µ–Ω–∞
        for keyword in academic_keywords:
            if keyword in email_domain.lower():
                score += 0.2
                break
        
        for keyword in medical_keywords:
            if keyword in email_domain.lower():
                score += 0.15
                break
        
        for keyword in tech_keywords:
            if keyword in email_domain.lower():
                score += 0.1
                break
        
        return min(1.0, score)
    
    def _extract_domain_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω –∏–∑ URL"""
        if '://' in url:
            return url.split('://')[1].split('/')[0]
        return url.split('/')[0] if url else ''
    
    def _determine_confidence_level(self, relevance_score: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –≤—ã–±–æ—Ä–µ"""
        if relevance_score >= 0.8:
            return "very_high"
        elif relevance_score >= 0.65:
            return "high"
        elif relevance_score >= 0.5:
            return "medium"
        elif relevance_score >= 0.3:
            return "low"
        else:
            return "very_low"
    
    def _post_process_ranking(self, 
                            candidates: List[ORCIDCandidate], 
                            context: str,
                            email: str,
                            target_name: Optional[str]) -> List[ORCIDCandidate]:
        """–ü–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if not candidates:
            return candidates
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª
        refined_candidates = self._apply_context_rules(candidates, context)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        verified_candidates = self._verify_top_candidates(refined_candidates, email, target_name)
        
        return verified_candidates
    
    def _apply_context_rules(self, 
                           candidates: List[ORCIDCandidate], 
                           context: str) -> List[ORCIDCandidate]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞"""
        
        for candidate in candidates:
            if context == "academic":
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤—ã—Å–æ–∫–æ–º—É h-index –∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                if candidate.h_index > 20 and candidate.temporal_score > 0.7:
                    candidate.relevance_score *= 1.1
            
            elif context == "corporate":
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–æ–º–µ–Ω–Ω–æ–π –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏
                if candidate.domain_affinity_score > 0.7:
                    candidate.relevance_score *= 1.15
            
            elif context == "personal":
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏–º–µ–Ω–∏
                if candidate.name_similarity_score > 0.8:
                    candidate.relevance_score *= 1.2
        
        # –ü–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
        candidates.sort(key=lambda x: x.relevance_score, reverse=True)
        return candidates
    
    def _verify_top_candidates(self, 
                             candidates: List[ORCIDCandidate],
                             email: str,
                             target_name: Optional[str]) -> List[ORCIDCandidate]:
        """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""
        if not candidates:
            return candidates
        
        top_candidate = candidates[0]
        
        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if top_candidate.confidence_level in ["very_low", "low"]:
            logger.warning(f"‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –≤—ã–±–æ—Ä–µ ORCID {top_candidate.orcid_id}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–∞–∑—Ä—ã–≤–∞ –≤ –æ—Ü–µ–Ω–∫–∞—Ö
        if (len(candidates) > 1 and 
            candidates[0].relevance_score - candidates[1].relevance_score > 0.2):
            logger.info(f"‚úÖ –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑—Ä—ã–≤ –≤ –æ—Ü–µ–Ω–∫–∞—Ö")
        
        return candidates
    
    def _log_ranking_results(self, candidates: List[ORCIDCandidate], email: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logger.info(f"\nüèÜ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è {email}:")
        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(candidates)}")
        
        for i, candidate in enumerate(candidates[:5]):  # –¢–æ–ø-5
            logger.info(
                f"  {i+1}. ORCID: {candidate.orcid_id} | "
                f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {candidate.relevance_score:.3f} | "
                f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {candidate.confidence_level} | "
                f"–ò–º–µ–Ω–∞: {candidate.name_similarity_score:.3f}"
            )
    
    def get_best_orcid(self, 
                      candidates: List[Dict[str, Any]], 
                      email: str,
                      context: str = "academic",
                      target_name: Optional[str] = None,
                      orcid_service=None) -> Optional[str]:
        """
        –£–¥–æ–±–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ª—É—á—à–µ–≥–æ ORCID ID
        
        Returns:
            ORCID ID –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏–ª–∏ None
        """
        ranked_candidates = self.rank_orcid_candidates(
            candidates=candidates,
            email=email,
            context=context,
            target_name=target_name,
            orcid_service=orcid_service
        )
        
        if ranked_candidates and ranked_candidates[0].confidence_level not in ["very_low"]:
            return ranked_candidates[0].orcid_id
        
        return None
